{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Wel5CbZ3Jx"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBP7yYofZzkD",
        "outputId": "a6e67196-0462-4fd0-ee2b-03d53df89016"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZA4L8GjQbQ8z"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Embedding, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IXvC6ifdEIh"
      },
      "source": [
        "# **Read Text File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P5SVtaUidCpw"
      },
      "outputs": [],
      "source": [
        "poem_file = open('C:/Users/Ghost/Desktop/gits/Nepali_Poem_Generator/datasets/poem.txt','r')\n",
        "poem = poem_file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcjNaznxdJVV"
      },
      "source": [
        "# **Read Word2Vec Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eTN93nnLhcTM"
      },
      "outputs": [],
      "source": [
        "w2vec_model= Word2Vec.load(\"C:/Users/Ghost/Desktop/gits/Nepali_Poem_Generator/w2vec/langauge_models/nepaliW2V_5Million.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBbioQVseAnk"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72gmZQqTfUG7"
      },
      "source": [
        "## Read numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WmEfXOqreAOV"
      },
      "outputs": [],
      "source": [
        "nepali_num_file=open(\"C:/Users/Ghost/Desktop/gits/Nepali_Poem_Generator/preprocess/numbers.txt\",\"r\",encoding=\"utf-8\")\n",
        "nepali_num=nepali_num_file.read()\n",
        "nepali_num=nepali_num.split(\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYp-LamBfWxl"
      },
      "source": [
        "## Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9OoXBl7fKDW",
        "outputId": "426963a7-92fa-44b2-e37a-f67158c9b362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['नछाडी जानोस् हे मेरा प्राण ! अकेली मलाई,', 'मनको वनमा ननिभ्ने गरी विरह जलाई !', 'ननिभ्ने गरी विरह जलाई,', 'लोचनका तारा ! हे मेर प्यारा ! यो जोति  बिलाए !', 'के भनूँ? भन्ने म केही थिइन  विष नै पिलाए !']\n"
          ]
        }
      ],
      "source": [
        "poem_corpus = poem.split(\"\\n\")\n",
        "print(poem_corpus[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyc5ez5Afmbs"
      },
      "source": [
        "## Apply Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D4d7X8AkfLQT"
      },
      "outputs": [],
      "source": [
        "def remove_puncutations_and_noise(sentences):\n",
        "    punctuations_and_noise = ['।', ',', ';', '?', ' !',' ! ' '!', '—', '-', '.',\"’\",\"‘\",\"'\",\"”\",'\\u200d']\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        for punct in punctuations_and_noise:\n",
        "            sentence = sentence.replace(punct,'')\n",
        "        processed_sentences.append(sentence)\n",
        "\n",
        "    return processed_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP5Rrr_nfMwq",
        "outputId": "6582103a-a9dc-4015-9afb-3968792ce8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['नछाडी जानोस् हे मेरा प्राण अकेली मलाई', 'मनको वनमा ननिभ्ने गरी विरह जलाई', 'ननिभ्ने गरी विरह जलाई', 'लोचनका तारा हे मेर प्यारा यो जोति  बिलाए', 'के भनूँ भन्ने म केही थिइन  विष नै पिलाए']\n"
          ]
        }
      ],
      "source": [
        "processed_poem_corpus = remove_puncutations_and_noise(poem_corpus)\n",
        "print(processed_poem_corpus[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuYBctkZgV3A"
      },
      "source": [
        "# **Make Corpus Ready to Fit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCaysagtgVZH",
        "outputId": "8e9cb04d-bfb1-43bd-898e-46f0a1220857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE FOR 0.0 LAKHS LINES\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import snowballstemmer\n",
        "mainlist = list()\n",
        "class Main_Data_list:\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.noise_list = ['\\n','\\ufeff','0','1','2','3','4','5','6','7','8','9','०','१','२','३','४','५','६','७','८','९','१०','।', ',', ';', '?', ' !', \"”\",' ! ' '!', '—', '-', '.',\"’\",\"‘\",\"'\",'\\u200d']\n",
        "        self.mainlist = []\n",
        "\n",
        "        self.stemmer = snowballstemmer.NepaliStemmer()\n",
        "\n",
        "    def simple_tokenizer(self,text) -> list:\n",
        "\n",
        "        line = re.sub('[।]',\"\", text)\n",
        "\n",
        "        devanagari_range = r'[\\u0900-\\u097F\\\\]'\n",
        "        def getDevanagariCharCount(token):\n",
        "            return len(list(filter(lambda char: re.match(devanagari_range, char), (char for char in token))))\n",
        "        def isDevanagari(token):\n",
        "            return True if getDevanagariCharCount(token) >= len(token)/2 else False\n",
        "\n",
        "        tokens = list(filter(lambda t: isDevanagari(t), line.split(\" \")))\n",
        "        return tokens\n",
        "\n",
        "    def get(self):\n",
        "        for i,line in enumerate(self.dataset[0:2000000]):\n",
        "\n",
        "            wordsList = self.simple_tokenizer(line)\n",
        "            words1 = [w for w in wordsList if not w in self.noise_list]\n",
        "            words1.append('')\n",
        "            words = []\n",
        "            for word in words1:\n",
        "              words.append([word.replace(noise,'') for noise in self.noise_list][0])\n",
        "              self.mainlist.append(words)\n",
        "\n",
        "            if i % 100000 == 0:\n",
        "                print(f\"DONE FOR {i/100000} LAKHS LINES\")\n",
        "        return self.mainlist\n",
        "\n",
        "final = Main_Data_list(processed_poem_corpus)\n",
        "mainlist = final.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO2ceWRBdq_R"
      },
      "source": [
        "# **Fit Word2Vec Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_phWSPrdkco",
        "outputId": "031841d4-0a0a-41ec-ff51-425a1376d546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(612473, 780460)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2vec_model.build_vocab(mainlist, update=True)\n",
        "w2vec_model.train(mainlist, total_examples=w2vec_model.corpus_count, epochs=w2vec_model.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0C6aP-wZFdi",
        "outputId": "634cd30f-f16b-4927-ba5a-841a491d5595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(293154, 200)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_weights = w2vec_model.wv.vectors\n",
        "vocab_size, embedding_size = trained_weights.shape\n",
        "vocab_size, embedding_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FApk0jHG9_40"
      },
      "source": [
        "# **Create Train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2r42SWpa77J",
        "outputId": "78013167-124f-470e-abb0-7b32fe05ac36"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "embedding_list = []\n",
        "for line in processed_poem_corpus:\n",
        "  embedding_list.append([list(w2vec_model.wv[word]) for word in line.split()])\n",
        "\n",
        "max_sequence_len = max([len(x) for x in embedding_list])\n",
        "\n",
        "for embeddings in embedding_list:\n",
        "  for i in range(1, len(embeddings)):\n",
        "    embedding_seq = embeddings[: i+1]\n",
        "    padded_sequence = np.zeros((max_sequence_len, embedding_size), dtype=np.float_)\n",
        "\n",
        "    for index,_ in enumerate(embedding_seq):\n",
        "      insert_index = max_sequence_len - len(embedding_seq) + index\n",
        "      padded_sequence[insert_index] = embedding_seq[index]\n",
        "\n",
        "    input_sequences.append(padded_sequence)\n",
        "\n",
        "input_sequences = np.array(input_sequences, dtype=np.object_)\n",
        "predictors, label = input_sequences[:, :-1],input_sequences[:, -1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictors = np.asarray(predictors).astype(np.float32)\n",
        "label = np.asarray(label).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfjPL3wvehUg",
        "outputId": "dbf7fde1-f5fc-404b-a56a-140da454d900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "नछाडी जानोस् हे मेरा प्राण अकेली मलाई\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('जानोस्', 0.9999999403953552)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(processed_poem_corpus[0])\n",
        "similar_words = w2vec_model.wv.similar_by_vector( np.array(predictors[1][-2]), topn=1)\n",
        "\n",
        "similar_words = w2vec_model.wv.similar_by_vector( np.array(predictors[1][-1]), topn=1)\n",
        "\n",
        "similar_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.21607383, -0.04870717,  0.05236128, ...,  0.08642674,\n",
              "        -0.10928017,  0.08665729]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictors[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FKOPvC3cX_v",
        "outputId": "059e6420-273d-4e91-8a38-f32f4b755065"
      },
      "outputs": [],
      "source": [
        "# # predictors = tf.convert_to_tensor(predictors, dtype=tf.float32)\n",
        "# # labels = tf.convert_to_tensor(label, dtype=tf.float32)\n",
        "# predictors[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeV255OoYKt_"
      },
      "source": [
        "# **Build LSTM models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 10, 150)           210600    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 10, 300)           361200    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 300)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               20200     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 752400 (2.87 MB)\n",
            "Trainable params: 752400 (2.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "input_dim = (max_sequence_len - 1, embedding_size)\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layer with return_sequences=True for sequence generation\n",
        "model.add(LSTM(150, input_shape=input_dim, return_sequences=True))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(embedding_size, activation='linear',  # Adjusted the activation here\n",
        "                kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.compile(loss='mse',  # Changed the loss function to mean squared error\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCJwq6sZ8x8Z",
        "outputId": "08afc818-eab0-4926-d07e-85bd72ee1666"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_size + 1, 100, input_length=max_sequence_len - 1))\n",
        "# model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(100))\n",
        "# model.add(Dense(emdedding_size, activation='linear',  # Adjusted the activation here\n",
        "#                 kernel_regularizer=regularizers.l2(0.01)))\n",
        "# model.compile(loss='mse',  # Changed the loss function to mean squared error\n",
        "#               optimizer='adam', metrics=['accuracy'])\n",
        "# print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "v-Ld-SoCcJRW",
        "outputId": "b1939450-c296-44a4-e551-024c9655ad45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11812/11812 [==============================] - 238s 19ms/step - loss: 0.6003 - accuracy: 0.0816 - val_loss: 0.5582 - val_accuracy: 0.0708\n",
            "Epoch 2/500\n",
            " 4903/11812 [===========>..................] - ETA: 1:56 - loss: 0.6017 - accuracy: 0.0844"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Ghost\\Desktop\\gits\\Nepali_Poem_Generator\\w2vec\\trainingLSTMwW2Vec.ipynb Cell 31\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ghost/Desktop/gits/Nepali_Poem_Generator/w2vec/trainingLSTMwW2Vec.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ghost/Desktop/gits/Nepali_Poem_Generator/w2vec/trainingLSTMwW2Vec.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(predictors, label, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m , verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
            "File \u001b[1;32mc:\\Users\\Ghost\\anaconda3\\envs\\fuse_machines\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=100, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(predictors, label, epochs=500, batch_size= 1 , verbose=1, validation_split=0.2, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd_NOxGruiEA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "       list([0.21927229, -0.056478217, 0.060117915, -0.037925318, -0.13777573, -0.057317194, -0.07726518, 0.07834977, -0.007228161, -0.18599378, -0.16449532, -0.0002100825, 0.064958744, 0.10180828, 0.003921977, -0.06316593, 0.017740157, 0.065559484, 0.11922026, -0.039086472, 0.074046224, -0.036231853, 0.01534304, 0.04818608, 0.006743838, -0.25357458, 0.13440284, -0.016839337, -0.00096636376, 0.1255406, 0.060458858, -0.01191231, 0.02501321, 0.031469624, -0.021567931, -0.18737431, -0.051946122, 0.06698385, 0.039512694, 0.04450356, 0.06749839, 0.09726132, -0.100591086, 0.025240183, -0.10920636, -0.028276535, -0.16780567, -0.046132654, 0.044618323, -0.06237182, -0.10258083, 0.10996795, -0.1794217, 0.02424799, -0.010753302, 0.04090991, -0.031017533, 0.022069093, 0.06129545, -0.06201478, -0.06716515, -0.062729836, -0.0024193488, -0.009916899, -0.060892146, -0.039804492, -0.011431253, -0.16640712, -0.15059566, -0.14573205, -0.1517604, 0.14601587, 0.043889444, -0.058958627, -0.06740363, -0.3048109, 0.13573553, -0.0432155, 0.017161181, -0.3132158, 0.073235005, 0.049295604, 0.10311902, 0.00022426633, 0.10189963, -0.03849319, 0.07399602, -0.1000927, 0.034886498, 0.0359571, 0.06230345, 0.09552662, -0.02826969, -0.054317944, 0.035638418, -0.014898055, 0.074846916, 0.019312544, 0.049670875, 0.04444306, 0.035361737, 0.16908479, 0.040680584, -0.07744357, -0.000383379, 0.013182245, 0.086256884, 0.1290183, 0.044994842, -0.1723522, 0.009916874, -0.16773634, 0.08606789, -0.032308742, -0.09793042, 0.004477377, 0.15202047, 0.05041037, -0.0134893125, 0.13152142, 0.032660976, -0.038491014, 0.15725085, -0.19776371, -0.19786577, 0.15228358, -0.2326982, 0.09420197, 0.034533657, -0.005174623, 0.20620468, 0.08024133, 0.22338307, -0.026008572, -0.05404602, 0.15144299, 0.08061778, 0.028853541, -0.13772677, 0.0037320643, 0.03810141, 0.06858284, 0.12854716, -0.08310836, -0.09123783, 0.15367806, 0.050830014, -0.100364886, 0.037717216, 0.13388741, 0.18256792, -0.11433347, 0.17299022, -0.0950132, 0.07445285, -0.14896652, 0.051923264, -0.019179935, -0.053554274, -0.15412116, -0.12564272, 0.108980194, -0.036079478, -0.051811542, 0.048537645, 0.0053936937, 0.18961564, -0.03211225, 0.12124787, 0.06160884, -0.19020237, 0.016605217, -0.046965975, -0.11699048, 0.059970997, 0.15352887, 0.09273445, -0.04885862, -0.012472862, 0.18187049, -0.044207275, 0.21682608, -0.07367325, -0.10707531, -0.06262233, -0.1883464, -0.13281415, -0.056698255, -0.06498914, -0.008520516, 0.17536315, 0.08055781, 0.038789432, -0.1398152, 0.09238968, 0.11606066, -0.025985725, 0.081792034, -0.1164486, 0.092759326]),\n",
              "       list([0.011171431, 0.08529836, 0.28305122, 0.22507045, -0.14128885, 0.007958646, -0.22972585, 0.107552774, -0.18775712, -0.062832445, 0.10754667, 0.042601746, 0.2142244, 0.38785613, 0.09419721, -0.0631417, 0.037862692, -0.023367513, -0.03626137, -0.35141778, 0.11894357, 0.009527308, 0.032303914, 0.15212466, 0.057575587, -0.16171633, 0.06425627, -0.080442615, -0.1139354, 0.21432078, 0.026298717, 0.072893456, -0.015053235, -0.03842067, -0.030886907, -0.097830355, 0.061253898, 0.04812406, 0.04681481, -0.031371053, 0.15269087, 0.078761935, -0.12845428, -0.13129936, 0.025590314, -0.059539348, -0.01865214, -0.13630193, 0.011294526, -0.05014632, -0.10765186, 0.18503764, -0.043268226, 0.07612734, -0.12944783, -0.039869998, 0.011195465, -0.08833752, -0.22915876, -0.15815397, 0.26607558, 0.00231935, 0.07641929, -0.14119971, -0.24313451, -0.062982894, -0.10886019, -0.016629845, -0.23047978, -0.027876208, 0.04908185, -0.10360587, 0.1731842, -0.10834977, -0.08790398, 0.019419422, 0.0055736857, -0.113884374, -0.113798015, -0.12654471, 0.06427837, 0.06493291, 0.040460784, 0.096414, -0.15456948, -0.067618154, 0.055039663, -0.026403392, -0.053791136, 0.038782325, 0.24309295, 0.086534254, 0.025640659, -0.097300574, -0.028383847, -0.14079334, -0.10747203, -0.056442194, -0.041596618, 0.027223602, -0.12100911, -0.03469375, -0.10034588, -0.12750384, 0.013135612, -0.0024109392, -0.077574246, -0.0029044212, -0.009894968, -0.19385639, 0.18542513, -0.2442089, -0.052690126, 0.06403261, -0.13172325, 0.023550285, 0.02612115, -0.18851139, 0.060546193, 0.03661271, 0.07880255, 0.16121249, 0.20494482, -0.17279868, -0.023157317, 0.083443336, -0.282027, 0.10765566, -0.2220167, 0.14151005, 0.11368886, 0.027041985, -0.13566011, -0.070468344, -0.084891304, 0.111814484, -0.017265871, 0.02208466, -0.17976336, -0.07314204, -0.02314584, -0.26555663, -0.1979823, 0.11473597, -0.18919776, 0.063142404, 0.025770614, -0.08907282, 0.07867083, -0.14156166, 0.18302797, -0.3171201, 0.22106354, 0.0001928805, -0.03856877, -0.043884806, 0.008475195, -0.07700252, -0.09069947, -0.24907905, -0.008605165, 0.18960337, -0.14182925, -0.0328074, 0.12424719, 0.026790576, 0.17597339, -0.19689026, 0.100433424, 0.12785423, -0.11730802, 0.07070866, -0.1635204, -0.17959273, 0.14843749, 0.025658943, -0.11433367, 0.03948514, 0.2606576, 0.059494775, 0.025392078, -0.026459103, 0.016544364, -0.24260615, -0.0502516, -0.19668971, -0.2158055, -0.19713709, 0.17581177, -0.061376352, 0.09340069, 0.10182533, 0.13427117, -0.0978921, 0.046975046, 0.03541145, -0.09078964, 0.08452879, -0.08464611, 0.1264301])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save(\"lstm_w2vec.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
