{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uenj8pUEetvk",
        "outputId": "d8664683-5a86-4c57-b692-792a4e7eb4c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "wstbbMazc2Tc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HcmvH-2xb1-Y"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Text"
      ],
      "metadata": {
        "id": "7NrGmVMEeqIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_file = open('/content/drive/MyDrive/poem/datasets/poem.txt','r')\n",
        "poem = poem_file.read()"
      ],
      "metadata": {
        "id": "13csQrtwc5Hn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem_corpus = poem.split(\"\\n\")\n",
        "print(poem_corpus[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqT3D19PfMFo",
        "outputId": "a51639df-8c18-4621-b5ca-48360ca252c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['‡§®‡§õ‡§æ‡§°‡•Ä ‡§ú‡§æ‡§®‡•ã‡§∏‡•ç ‡§π‡•á ‡§Æ‡•á‡§∞‡§æ ‡§™‡•ç‡§∞‡§æ‡§£ ! ‡§Ö‡§ï‡•á‡§≤‡•Ä ‡§Æ‡§≤‡§æ‡§à,', '‡§Æ‡§®‡§ï‡•ã ‡§µ‡§®‡§Æ‡§æ ‡§®‡§®‡§ø‡§≠‡•ç‡§®‡•á ‡§ó‡§∞‡•Ä ‡§µ‡§ø‡§∞‡§π ‡§ú‡§≤‡§æ‡§à !', '‡§®‡§®‡§ø‡§≠‡•ç‡§®‡•á ‡§ó‡§∞‡•Ä ‡§µ‡§ø‡§∞‡§π ‡§ú‡§≤‡§æ‡§à,', '‡§≤‡•ã‡§ö‡§®‡§ï‡§æ ‡§§‡§æ‡§∞‡§æ ! ‡§π‡•á ‡§Æ‡•á‡§∞ ‡§™‡•ç‡§Ø‡§æ‡§∞‡§æ ! ‡§Ø‡•ã ‡§ú‡•ã‡§§‡§ø  ‡§¨‡§ø‡§≤‡§æ‡§è !', '‡§ï‡•á ‡§≠‡§®‡•Ç‡§Å? ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ ‡§ï‡•á‡§π‡•Ä ‡§•‡§ø‡§á‡§®  ‡§µ‡§ø‡§∑ ‡§®‡•à ‡§™‡§ø‡§≤‡§æ‡§è !']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_noise(sentences):\n",
        "    punctuations = ['\\n','\\ufeff','0','1','2','3','4','5','6','7','8','9','‡•¶','‡•ß','‡•®','‡•©','‡•™','‡•´','‡•¨','‡•≠','‡•Æ','‡•Ø','‡•ß‡•¶','\\u200d']\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        for punct in punctuations:\n",
        "            sentence = sentence.replace(punct,'')\n",
        "        processed_sentences.append(sentence)\n",
        "\n",
        "    return processed_sentences"
      ],
      "metadata": {
        "id": "Psl7NidvfMVc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_poem_corpus = remove_noise(poem_corpus)\n",
        "print(processed_poem_corpus[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDtvXtE9fPrP",
        "outputId": "ec26c0b9-12bc-4703-a8c2-eb0c698cb705"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['‡§®‡§õ‡§æ‡§°‡•Ä ‡§ú‡§æ‡§®‡•ã‡§∏‡•ç ‡§π‡•á ‡§Æ‡•á‡§∞‡§æ ‡§™‡•ç‡§∞‡§æ‡§£ ! ‡§Ö‡§ï‡•á‡§≤‡•Ä ‡§Æ‡§≤‡§æ‡§à,', '‡§Æ‡§®‡§ï‡•ã ‡§µ‡§®‡§Æ‡§æ ‡§®‡§®‡§ø‡§≠‡•ç‡§®‡•á ‡§ó‡§∞‡•Ä ‡§µ‡§ø‡§∞‡§π ‡§ú‡§≤‡§æ‡§à !', '‡§®‡§®‡§ø‡§≠‡•ç‡§®‡•á ‡§ó‡§∞‡•Ä ‡§µ‡§ø‡§∞‡§π ‡§ú‡§≤‡§æ‡§à,', '‡§≤‡•ã‡§ö‡§®‡§ï‡§æ ‡§§‡§æ‡§∞‡§æ ! ‡§π‡•á ‡§Æ‡•á‡§∞ ‡§™‡•ç‡§Ø‡§æ‡§∞‡§æ ! ‡§Ø‡•ã ‡§ú‡•ã‡§§‡§ø  ‡§¨‡§ø‡§≤‡§æ‡§è !', '‡§ï‡•á ‡§≠‡§®‡•Ç‡§Å? ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ ‡§ï‡•á‡§π‡•Ä ‡§•‡§ø‡§á‡§®  ‡§µ‡§ø‡§∑ ‡§®‡•à ‡§™‡§ø‡§≤‡§æ‡§è !']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('processed_poem.txt','w') as f:\n",
        "  for line in processed_poem_corpus:\n",
        "    f.write(line + '\\n')"
      ],
      "metadata": {
        "id": "LJY1O6DqO-nB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune With GPT-2"
      ],
      "metadata": {
        "id": "5sSEsKiFfa9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset Function"
      ],
      "metadata": {
        "id": "ixuyoUaOPrqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path, tokenizer, block_size = 128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=mlm,\n",
        "    )\n",
        "    return data_collator\n"
      ],
      "metadata": {
        "id": "F4ERbeyOPrIb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Function"
      ],
      "metadata": {
        "id": "_ITK5MsPP0XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_file_path,model_name,\n",
        "          output_dir,\n",
        "          overwrite_output_dir,\n",
        "          per_device_train_batch_size,\n",
        "          num_train_epochs,\n",
        "          save_steps):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
        "  data_collator = load_data_collator(tokenizer)\n",
        "\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "  model.save_pretrained(output_dir)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "          output_dir=output_dir,\n",
        "          overwrite_output_dir=overwrite_output_dir,\n",
        "          per_device_train_batch_size=per_device_train_batch_size,\n",
        "          num_train_epochs=num_train_epochs,\n",
        "      )\n",
        "\n",
        "  trainer = Trainer(\n",
        "          model=model,\n",
        "          args=training_args,\n",
        "          data_collator=data_collator,\n",
        "          train_dataset=train_dataset,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  trainer.save_model()"
      ],
      "metadata": {
        "id": "L026aAp4fXIw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you need to set parameters\n",
        "train_file_path = \"/content/processed_poem.txt\"\n",
        "model_name = 'gpt2'\n",
        "output_dir = '/content/'\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 10\n",
        "save_steps = 500"
      ],
      "metadata": {
        "id": "2597D3MZlgYt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It takes about 30 minutes to train in colab.\n",
        "train(\n",
        "    train_file_path=train_file_path,\n",
        "    model_name=model_name,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=overwrite_output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "KYkYg1cIlsxt",
        "outputId": "792c05b7-718b-4f54-afd4-db08cd608ed0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1810' max='1810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1810/1810 09:23, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.634500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.442900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.362400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def generate_text(sequence, max_length):\n",
        "    model_path = \"/content/\"\n",
        "    model = load_model(model_path)\n",
        "    tokenizer = load_tokenizer(model_path)\n",
        "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
        "    final_outputs = model.generate(\n",
        "        ids,\n",
        "        do_sample=True,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=model.config.eos_token_id,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "O78IvYVEQQNQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = input() # oil price\n",
        "max_len = int(input()) # 20\n",
        "generate_text(sequence, max_len) # oil price for July June which had been low at as low as was originally stated Prices have since resumed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cmFUnF8T3UB",
        "outputId": "3dd67811-fd21-46c3-e2dd-13fa8c5c3121"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡§µ‡§ø‡§∑ ‡§®‡•à ‡§™‡§ø‡§≤‡§æ‡§è\n",
            "100\n",
            "‡§µ‡§ø‡§∑ ‡§®‡•à ‡§™‡§ø‡§≤‡§æ‡§è‡§® ‡•§\n",
            "‡§¶‡•á‡§ñ‡•ç‡§® ‡§™‡•ç‡§∞‡§æ‡§£! ‡§≠‡§® ‡§§‡§ø‡§Æ‡•Ä ‡§¨‡§ø‡§≤‡§æ‡§è‡§® ‡•§\n",
            "‡§¨‡§ö‡§æ‡§≤ ‡§∏‡•ç‡§µ‡§∞‡•ç‡§ó ‡§∏‡§æ‡§∞‡§æ ‡§öÔøΩ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "SdulMRl9UM2v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}